{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing text to find similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file found and working\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for sql handling\n",
    "import psycopg2\n",
    "import sql\n",
    "from sql import engine\n",
    "from sql import get_data\n",
    "\n",
    "# check text matching\n",
    "import Levenshtein                                              # install: with pip install Levenshtein\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity          # install: conda install sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk                                                     # install: conda install -c anaconda nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring all the titles from news table & create a function to check each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/sql-practice/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "news = get_data('SELECT * FROM  news_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text function \n",
    "\n",
    "def clean_titles(df):\n",
    "    clean_title = pd.Series([], dtype=pd.StringDtype())\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        text = ''.join([word for word in df['title_en'][row] if word not in string.punctuation])\n",
    "        text = text.lower()\n",
    "        text = ' '.join([word for word in df['title_en'][row].split() if word not in stopwords])\n",
    "        clean_title[row] = text\n",
    "        \n",
    "    df.insert(1, 'clean_title', clean_title)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe with clean titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = clean_titles(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create vectors from 2 titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create vectors from two titles\n",
    "\n",
    "def vectorize_function(title1, title2):\n",
    "    title_list = [title1, title2]\n",
    "    vectorizer = CountVectorizer().fit_transform(title_list)\n",
    "    vectors = vectorizer.toarray()\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the cosine similarity matrix of the two titles\n",
    "\n",
    "def cosine_matrix_function(vectors):\n",
    "    csim_titles = cosine_similarity(vectors)\n",
    "    return csim_titles \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to reshape\n",
    "\n",
    "def cosine_similarity_vectors_function(vec1, vec2):\n",
    "    vec1 = vec1.reshape(1,-1)\n",
    "    vec2 = vec2.reshape(1,-2)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to know similarity of titles\n",
    "\n",
    "def check_similarity(title1, title2):\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    #create vectors from two titles\n",
    "    vectors = vectorize_function(title1, title2)\n",
    "    \n",
    "    #calculate cosine from vectors\n",
    "    similarity = cosine_similarity_vectors_function(vectors[0], vectors[1])\n",
    "    \n",
    "    # check for result\n",
    "    if similarity == 0.0:\n",
    "        result = False\n",
    "    elif similarity > 0.7:\n",
    "        result = True\n",
    "    else:\n",
    "        result = 'inconclusive'\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to integrate all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter dataframe for similar news\n",
    "\n",
    "def filter_news(df):\n",
    "\n",
    "    df1 = df\n",
    "    df2 = df.copy()\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "\n",
    "        for index2, row2 in df2.iterrows():\n",
    "\n",
    "            title1 = row['clean_title']\n",
    "            title2 = row2['clean_title']\n",
    "\n",
    "            if index != index2:\n",
    "                \n",
    "                xyz = check_similarity(title1, title2)\n",
    "\n",
    "                if xyz == True:\n",
    "                    print('')\n",
    "                    print('-----------')\n",
    "                    print(title1)\n",
    "                    print(title2)\n",
    "                    print('-----------')\n",
    "                    df2.drop([index2], inplace=True)\n",
    "        \n",
    "    return df2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_news(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table, define schema and upload to SQL\n",
    "\n",
    "table_name = 'news_unique'\n",
    "schema = 'capstone'\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # change to 'append' \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c12cbf984401a473fdf5ad54be096b36364cb85034417d000695974821cc3f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sql-practice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
