{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean unwanted words from news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for sql handling\n",
    "import psycopg2\n",
    "import sql\n",
    "from sql import engine\n",
    "from sql import get_data\n",
    "\n",
    "# check text matching\n",
    "import Levenshtein                                              # install: with pip install Levenshtein\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity          # install: conda install sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk                                                     # install: conda install -c anaconda nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text function \n",
    "\n",
    "def clean_titles(df):\n",
    "    clean_title = pd.Series([], dtype=pd.StringDtype())\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        text = ''.join([word for word in df['title_en'][row] if word not in string.punctuation])\n",
    "        text = text.lower()\n",
    "        text = ' '.join([word for word in df['title_en'][row].split() if word not in stopwords])\n",
    "        clean_title[row] = text\n",
    "        \n",
    "    df.insert(1, 'clean_title', clean_title)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/sql-practice/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = get_data('SELECT * FROM table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean UNWANTED WORDS from dataframe\n",
    "\n",
    "unwanted_words = ['autos', 'luxury', 'ferrari', 'lamborghini', 'tennis', 'futbol', 'football', 'motor', 'suv', 'pickup', 'christies', 'rollex', 'rolex', 'bentley', 'snob', 'skoda', 'mitsubishi', 'motor vehicle', 'motor vehicles', 'hollywood', '4x4', 'electric rolls royce', 'formula one', 'phantom', 'fantom', 'aston martin', 'porsche', 'bmw', 'mercedes benz', 'expensive', 'toyota', 'kardashians', 'kardashian', 'league', 'cars', 'britney spears']\n",
    "\n",
    "def clean_unwanted_words(df):\n",
    "        \n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        # make title and body lower\n",
    "        lower_title = row['title_en'].lower()\n",
    "        lower_body = row['body_en'].lower()\n",
    "        \n",
    "        for word in unwanted_words:\n",
    "            \n",
    "            # look for the word in title and body\n",
    "            index_body = lower_body.find(word)\n",
    "            index_title = lower_title.find(word)\n",
    "            \n",
    "            # check if word is in title AND OR BODY and drop row:\n",
    "            if index_title != -1:\n",
    "                print(row['title_en'], '-----> unwanted word found in TITLE: ', word)\n",
    "                df.drop([idx], inplace=True)\n",
    "                break\n",
    "            elif index_body != -1:\n",
    "                print(row['title_en'], '-----> unwanted word found in BODY: ', word)\n",
    "                df.drop([idx], inplace=True)\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_unwanted_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table, define schema and upload to SQL\n",
    "\n",
    "table_name = 'news_clean'\n",
    "schema = 'capstone'\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # change to 'append' \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c12cbf984401a473fdf5ad54be096b36364cb85034417d000695974821cc3f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sql-practice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
